{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import openai\n",
    "import json\n",
    "import pdftotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_extract(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        pdf = pdftotext.PDF(f)\n",
    "    text = ''.join(pdf)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_extract(\"Tam_2.pdf\")\n",
    "with open(\"dataset/cv/sale_manager/0.txt\", 'w') as file:\n",
    "    file.write(text)\n",
    "prompt_template = f\"\"\"\n",
    "[Job Description]: \n",
    "\n",
    "{text}\n",
    "\n",
    "[Extract Requirements]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"jd2cv.txt\", \"r\") as file:\n",
    "    prompt = file.read()\n",
    "prompt_template += prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_api(text: str = None):\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = 'gpt-4',\n",
    "        messages = [\n",
    "                        {\"role\": \"user\", \n",
    "                         \"content\": text}\n",
    "                ],\n",
    "        temperature=1.0\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/jd/ai_engineer.txt\", \"r\") as file:\n",
    "    jd = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/cv/ai_engineer/0.txt\", \"r\") as file:\n",
    "    cv = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "[Job Description]\n",
    "{jd}\n",
    "\n",
    "[Resume]\n",
    "{cv}\n",
    "\n",
    "\n",
    "Please compare and score the similarity or match rate of the [Resume] and [Job Description] above. Check how many percent on a scale of 100 that [Resume] and [Job Description] match.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(cv=cv, jd=jd)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The match rate of the resume and the job description is around 20%. The candidate's background is in marketing and sales, whereas the job description is for a deep learning engineer role, which requires a highly technical skill set including experience with deep learning models, neural network architectures, and Python programming. The candidate's resume does not reflect any of these required skills or experiences. Therefore, this candidate would not be a good fit for the posted job based on the provided resume.\n"
     ]
    }
   ],
   "source": [
    "result = gpt_api(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   ***Evaluate CV-JD matching***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from pprint import pprint\n",
    "import json, openai\n",
    "import concurrent.futures\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def get_json_info(json_data: Dict, features: List[str], spec_features=List[str]):\n",
    "    data_str = \"\"\n",
    "    for feature, spec_feature in zip(features, spec_features):\n",
    "        data = json_data[feature]\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            for info in data:\n",
    "                if isinstance(info, dict) :                    \n",
    "                    if spec_feature in info.keys():                        \n",
    "                        if info[spec_feature] != \"N/A\":\n",
    "                            data_ext = \"; \".join(info[spec_feature])\n",
    "                            data_str += f\"{data_ext}\\n\"\n",
    "                    else:\n",
    "                        for val in info.values():\n",
    "                            if val != \"N/A\":\n",
    "                                data_ext = \"; \".join(val)\n",
    "                                data_str += f\"{data_ext}\\n\"\n",
    "                    data_str += \"\\n\"\n",
    "                elif isinstance(info, str) and info != \"N/A\":\n",
    "                    data_str += f\"{info}\\n\"\n",
    "        elif isinstance(data, dict):                  \n",
    "            if spec_feature in data.keys():                  \n",
    "                if data[spec_feature] != \"N/A\":\n",
    "                    data_ext = \"; \".join(data[spec_feature])\n",
    "                    data_str += f\"{data_ext}\\n\"\n",
    "            else:\n",
    "                for val in data.values():\n",
    "                    if val != \"N/A\":\n",
    "                        data_ext = \"; \".join(val)\n",
    "                        data_str += f\"{data_ext}\\n\" \n",
    "    return data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_lst = [\n",
    "             [ ([\"skills\"], [None]), ([\"skill_requirements\"], [None]) ],\n",
    "             [ ([\"education\"], [None]), ([\"education_requirements\"], [None]) ],\n",
    "             [ ([\"project\", \"experience\"], [None]*2), ([\"experience_requirements\"], [None]) ]\n",
    "            ]\n",
    "\n",
    "#   Please request extracted CV and JD API to get JSON file\n",
    "\n",
    "#   Read extracted CV file result\n",
    "with open(\"cv_be/data/cv/cv_extraction/100.json\", \"r\") as file:\n",
    "    cv_json = json.load(file)  \n",
    "\n",
    "#   Read extracted JD file result\n",
    "with open(\"cv_be/data/jd/jd_extraction/ai_engineer.json\", \"r\") as file:\n",
    "    jd_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Prompt template to evaluate pair of fields: Give match score and explanation for skill, education, and experience\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "[RESUME]\n",
    "{cv}\n",
    "\n",
    "[JOB DESCRIPTION]\n",
    "{jd}\n",
    "\n",
    "Please compare and score strictly the match rate (how many percent) of the contents of candidate in [RESUME] to all requirements mentioned [JOB DESCRIPTION] above?\n",
    "Give the explanation for the remaining percentage that isnot match\n",
    "\n",
    "Below is the JSON format that your response must strictly follows:\n",
    "\n",
    "{{\n",
    "    score:\n",
    "    explanation:\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "field_name = ['skill', 'education', 'experience']\n",
    "prompts = []\n",
    "for field in match_lst:\n",
    "    cv_data = get_json_info(cv_json, field[0][0], field[0][1])\n",
    "    jd_data = get_json_info(jd_json, field[1][0], field[1][1])\n",
    "    prompt = prompt_template.format(cv=cv_data, jd=jd_data)\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_api(text: str, name: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model = 'gpt-4',\n",
    "            messages = [\n",
    "                            {\"role\": \"user\", \n",
    "                            \"content\": text}\n",
    "                    ],\n",
    "            temperature=0.0\n",
    "            ).choices[0].message.content\n",
    "    return name, json.loads(response)\n",
    "\n",
    "def cal_avg(results):\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        scores.append(result[\"rate\"])\n",
    "    return round(sum(scores)/len(scores), 2)\n",
    "\n",
    "#   Call API service with parallel request\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(executor.map(gpt_api, prompts, field_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('skill',\n",
      "  {'explanation': 'The candidate has strong Python programming skills and '\n",
      "                  'experience with deep learning frameworks such as '\n",
      "                  'TensorFlow, PyTorch, and Keras, which matches the job '\n",
      "                  'requirements. They also have experience in computer vision '\n",
      "                  'and NLP, which is desirable for the job. The candidate also '\n",
      "                  'possesses problem-solving, communication, and teamwork '\n",
      "                  'skills, which are necessary for the role. However, there is '\n",
      "                  'no mention of experience in designing and implementing deep '\n",
      "                  'learning models, experience in neural network architectures '\n",
      "                  'for OCR tasks, understanding of machine learning concepts, '\n",
      "                  'optimization algorithms, and transfer learning techniques, '\n",
      "                  'and experience in preprocessing and augmenting data for '\n",
      "                  'deep learning. These missing qualifications account for the '\n",
      "                  '30% mismatch.',\n",
      "   'score': 70}),\n",
      " ('education',\n",
      "  {'explanation': \"The candidate has both a Bachelor's and Master's degree in \"\n",
      "                  'Computer Science Engineering, which matches the job '\n",
      "                  'description requirements perfectly. The job description '\n",
      "                  'mentions that a Ph.D. is a plus, not a requirement, so it '\n",
      "                  'does not affect the match rate.',\n",
      "   'score': 100}),\n",
      " ('experience',\n",
      "  {'explanation': 'The candidate has 4 years of experience as a Deep Learning '\n",
      "                  'Engineer, which includes experience in designing and '\n",
      "                  'implementing deep learning architectures for OCR tasks. '\n",
      "                  'However, the resume does not specifically mention '\n",
      "                  'experience with CNNs, RNNs, attention models, and '\n",
      "                  'transformer models, which are required in the job '\n",
      "                  'description.',\n",
      "   'score': 80})]\n"
     ]
    }
   ],
   "source": [
    "pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8446526157116455, 0.5574000342594208)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import openai\n",
    "# from numpy.linalg import norm\n",
    "\n",
    "# openai.api_key = \"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\"\n",
    "\n",
    "# def text_embedding(text):\n",
    "#     response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=text)\n",
    "#     return response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# a = np.asarray(text_embedding(cv_data))\n",
    "# b = np.asarray(text_embedding(jd_data))\n",
    "\n",
    "# cosine = np.dot(a, b)/(norm(a)*norm(b))\n",
    "# dist = np.linalg.norm(a - b)\n",
    "# cosine, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Create CV according to keywords***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "import random\n",
    "import concurrent.futures\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "if os.path.exists(\"data.txt\"):\n",
    "    os.remove(\"data.txt\")\n",
    "    time.sleep(1)\n",
    "\n",
    "JD_EXTRACTION_PATH = 'cv_be/data/jd/jd_extraction'\n",
    "jd_name = 'ai_engineer.json'\n",
    "with open(os.path.join(JD_EXTRACTION_PATH, jd_name), \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "#   Extract each field from extracted JD file\n",
    "skills = data[\"skill_requirements\"]\n",
    "resp = data[\"responsibilities\"]\n",
    "edu = data[\"education_requirements\"]\n",
    "exper = data[\"experience_requirements\"]\n",
    "title = data[\"job_title\"]\n",
    "summary = data[\"job_summary\"]   \n",
    "\n",
    "skills = skills + resp  #   Skills = skill + responsibilities \n",
    "experience = exper\n",
    "education = edu\n",
    "\n",
    "jd_data = [skills, experience, education]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" \\n- Please extract [Job Description] below into one string of keywords (one by one word) needed for a job description. Each keyword is separated with \\n character.\\n- Job description is a written document that provides an overview of the tasks, responsibilities, qualifications, and expectations associated with a specific job role within an organization.\\n- Please DO NOT index these keywords results\\n\\n[Job Description]\\n\\n['Strong experience in designing and implementing deep learning models using frameworks such as TensorFlow, PyTorch, or Keras.', 'Has 3-4 years of experience in neural network architectures for OCR tasks, including CNNs, RNNs, attention models, and transformer models.', 'Solid understanding of machine learning and deep learning concepts, optimization algorithms, and transfer learning techniques.', 'Experience in preprocessing and augmenting data for deep learning, including image processing, text normalization, and data augmentation techniques.', 'Strong programming skills in Python and familiarity with relevant libraries and tools for deep learning.', 'Experience with computer vision and natural language processing (NLP) techniques is desirable.', 'Ability to work effectively in a collaborative, cross-functional team environment and excellent problem-solving skills.', 'Strong communication skills to convey complex technical concepts and collaborate with team members.', 'Design and implement deep learning architectures for OCR tasks, including character recognition, text extraction, and document analysis.', 'Train and optimize neural network models using large-scale datasets and apply transfer learning techniques for domain-specific adaptations.', 'Conduct data preprocessing and augmentation to enhance model performance and generalization capabilities.', 'Evaluate and benchmark OCR models using appropriate evaluation metrics and design experiments to analyze and improve model performance.', 'Collaborate with software engineers and DevOps team to integrate trained models into deployment pipelines and ensure smooth production deployment.', 'Explore techniques for model interpretability and explainability to provide insights into the OCR system’s decision-making process.', 'Stay up-to-date with the latest advancements in deep learning, OCR techniques, and related research areas.']\\n\\n\", \" \\n- Please extract [Job Description] below into one string of keywords (one by one word) needed for a job description. Each keyword is separated with \\n character.\\n- Job description is a written document that provides an overview of the tasks, responsibilities, qualifications, and expectations associated with a specific job role within an organization.\\n- Please DO NOT index these keywords results\\n\\n[Job Description]\\n\\n['Has 3-4 years of experience in neural network architectures for OCR tasks, including CNNs, RNNs, attention models, and transformer models.']\\n\\n\", \" \\n- Please extract [Job Description] below into one string of keywords (one by one word) needed for a job description. Each keyword is separated with \\n character.\\n- Job description is a written document that provides an overview of the tasks, responsibilities, qualifications, and expectations associated with a specific job role within an organization.\\n- Please DO NOT index these keywords results\\n\\n[Job Description]\\n\\n['Bachelor’s or Master’s degree in Computer Science, Engineering, or a related field. A Ph.D. in a relevant field is a plus.']\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "#   Below is a prompt template to extract keywords in each field of a JD\n",
    "\n",
    "prompt_template = \"\"\" \n",
    "- Please extract [Job Description] below into one string of keywords (one by one word) needed for a job description. Each keyword is separated with \\n character.\n",
    "- Job description is a written document that provides an overview of the tasks, responsibilities, qualifications, and expectations associated with a specific job role within an organization.\n",
    "- Please DO NOT index these keywords results\n",
    "\n",
    "[Job Description]\n",
    "\n",
    "{jd}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompts = []\n",
    "for data in jd_data:\n",
    "    prompt = prompt_template.format(jd=data)\n",
    "    prompts.append(prompt)\n",
    "\n",
    "#   Get results\n",
    "def gpt_api(text: str, name: str):\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model = 'gpt-4',\n",
    "            messages = [\n",
    "                            {\"role\": \"user\", \n",
    "                            \"content\": text}\n",
    "                    ],\n",
    "            temperature=0.0\n",
    "            ).choices[0].message.content\n",
    "    return name, response\n",
    "\n",
    "#   Call parallel request for 3 fields: \"skills\", \"experience\", \"education\"\n",
    "fields = [\"skills\", \"experience\", \"education\"]\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    results = list(executor.map(gpt_api, prompts, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> skills:\n",
      "Strong experience, designing, implementing, deep learning models, TensorFlow, PyTorch, Keras, 3-4 years of experience, neural network architectures, OCR tasks, CNNs, RNNs, attention models, transformer models, Solid understanding, machine learning, deep learning concepts, optimization algorithms, transfer learning techniques, Experience, preprocessing, augmenting data, deep learning, image processing, text normalization, data augmentation techniques, Strong programming skills, Python, familiarity, relevant libraries, tools, deep learning, Experience, computer vision, natural language processing, NLP, Ability, work effectively, collaborative, cross-functional team environment, excellent problem-solving skills, Strong communication skills, convey, complex technical concepts, collaborate, team members, Design, implement, deep learning architectures, OCR tasks, character recognition, text extraction, document analysis, Train, optimize, neural network models, large-scale datasets, apply, transfer learning techniques, domain-specific adaptations, Conduct, data preprocessing, augmentation, enhance, model performance, generalization capabilities, Evaluate, benchmark, OCR models, appropriate evaluation metrics, design experiments, analyze, improve, model performance, Collaborate, software engineers, DevOps team, integrate, trained models, deployment pipelines, ensure, smooth production deployment, Explore, techniques, model interpretability, explainability, provide insights, OCR system’s decision-making process, Stay up-to-date, latest advancements, deep learning, OCR techniques, related research areas.\n",
      ">> experience:\n",
      "3-4 years, experience, neural network architectures, OCR tasks, CNNs, RNNs, attention models, transformer models.\n",
      ">> education:\n",
      "Bachelor’s, Master’s, degree, Computer Science, Engineering, related field, Ph.D., relevant field, plus.\n"
     ]
    }
   ],
   "source": [
    "#   Show extracted keywords result\n",
    "for result in results:\n",
    "    print(f\">> {result[0]}:\\n{result[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Create a dummy CV with percentage of random words in keywords (Only choose random for Education, Experience, Responsibilities_Skill)\n",
    "#   But a dummy CV will have fully 5 fields: [Job title, Education, Experience, Resibonsibilities_Skill and Job Summary]\n",
    "\n",
    "skills = results[0][1].split(\",\")\n",
    "experience = results[1][1].split(\",\")\n",
    "education = results[2][1].split(\",\")\n",
    "\n",
    "info_qua = 100      #   [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "prompt = \"\"\"\"\"\"\n",
    "#   Add job title\n",
    "prompt += f\"Job title: {',  '.join(title)}\\n\"\n",
    "#   Add Education Requirements\n",
    "prompt += \"\\nEducation requirements\\n  Below are some keywords of requirements needed for Education in the CV that you should generate the detailed information relevant to them\"\n",
    "edu_ran = random.sample(education, int(info_qua/100*len(education)))\n",
    "prompt += '\\n  - '\n",
    "prompt += '\\n  - '.join(edu_ran)\n",
    "prompt += '\\n'\n",
    "\n",
    "#   Add Experience Requirements\n",
    "prompt += \"\\nExperience requirements\\n  Below are some keywords of requirements needed for Experience in the CV that you should generate the detailed information relevant to them\"\n",
    "exper_ran = random.sample(experience, int(info_qua/100*len(experience)))\n",
    "prompt += '\\n  - '\n",
    "prompt += '\\n  - '.join(exper_ran)\n",
    "prompt += '\\n'\n",
    "\n",
    "#   Add Skill Requirements\n",
    "prompt += \"\\nResponsibilities and Skill requirements\\n  Below are some keywords of requirements needed for Responsibilities and Skill in the CV that you should generate the detailed information relevant to them\"\n",
    "skill_ran = random.sample(skills, int(info_qua/100*len(skills)))\n",
    "prompt += '\\n  - '\n",
    "prompt += '\\n  - '.join(skill_ran)\n",
    "prompt += '\\n'\n",
    "#   Add Job Summary\n",
    "prompt += \"\\nJob Summary\\n\"\n",
    "prompt += ',  - '.join(summary)\n",
    "\n",
    "jd_template = \"\"\"[Job Description]\n",
    "\n",
    "{jd}\n",
    "\n",
    "- Only use explicit keywords provided in [Job Description] above, please create a CV that matches ONE HUNDRED percent exactly with each keyword mentioned in [Job Description].\n",
    "- The generated CV will have the underlying following fields: Personal Information, Education, Work Experience, Skill.\n",
    "- Please give highly attention to keywords in the Education, Experience, Responsibilities and Skill requirement fields in [Job Description], you can generate detailed information or more evidences about these keywords to get best results. \n",
    "\"\"\"\n",
    "\n",
    "#   A keyword_CV will save with the name as \"data.txt\"\n",
    "jd = jd_template.format(jd=prompt)\n",
    "with open(\"data.txt\", 'w') as file:\n",
    "    file.write(jd)\n",
    "    \n",
    "#   Copy the whole content in data.txt file and paste to POE(GPT-3.5-turbo, GPT-4) to generate a dummy CV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
